# websucker Quickstart

**websucker** takes websites, recursively scans all their subpages, and outputs each subpage to a text file and/or summarizes each subpage. This tool should not be used on sites requesting crawling exclusion on their `robots.txt`.
